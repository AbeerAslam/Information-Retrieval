bayesian unif of gradient and bandit base learn acceler global optimis global optim , multi arm bandit , on line learn , multi strategi learn bandit base optimis scheme remark advantag over gradient base approach due their global perspect , which elimin danger of get stuck local optima . howev , continu optimis problem or problem with larg number of action , bandit base approach hinder by slow learn . gradient base approach , other hand , navig quickli high dimension continu space through local optimis , follow gradient fine grain step . howev , apart from be suscept local optima , these scheme also less suit onlin learn due their relianc extens trial and error befor optimum identifi . contrast , bandit algorithm seek identifi optim action ( global optima ) few step possibl . thi paper , propos bayesian approach that unifi abov two distinct paradigm one singl framework , with aim of combin their advantag . heart of our approach find stochast linear approxim of function optimis , where both gradient and valu of function explicitli captur . thi model allow us learn from both noisi function and gradient observ , well predict these properti across action space support optimis . further propos an accompani bandit driven explor scheme that use bayesian credibl bound trade off explor against exploit . our empir result demonstr that by unifi bandit and gradient base learn , one obtain consist improv perform across wide spectrum of problem environ . furthermor , even when gradient feedback is unavail , flexibl of our model , includ gradient predict , still allow us outperform compet approach , although with smaller margin .