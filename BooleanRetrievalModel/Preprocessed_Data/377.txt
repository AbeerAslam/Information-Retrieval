direct multiclass boost use base classifi ' posterior probabl estim machin learn , boost , margin , multiclass classif present new multiclass boost algorithm call adaboost.bg . like origin freund and shapir 's adaboost algorithm , it aggreg tree but instead of use their misclassif error it take into account margin of observ , which may seen confid measur of their predict , rather then their correct . prove effici of our algorithm by simul and compar it similar approach known minim global margin of final classifi .