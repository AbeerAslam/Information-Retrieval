improving performance problem with few labelled data by reusing stacked auto encoders transfer learning deep learning artificial neural network deep architecture been used transfer learning application with aim of improving performance of network designed given problem by reusing knowledge from another problem this work addressed transfer of knowledge between deep network used classifier of digit and shape image considering case where only set of class label or only data distribution changed from source target problem our main goal wa study how performance of knowledge transfer between such problem would affected by varying number of layer being retrained and amount of data used that retraining generally reusing network trained different label set led better result than reusing network trained different data distribution particular reusing less class network trained more class wa beneficial virtually any amount of training data case retraining only one layer save time consistently led poorer performance result obtained when retraining upright digit network trained rotated digit raise hypothesis that transfer learning could used better deal with image classification problem which only small amount of labelled data is available training