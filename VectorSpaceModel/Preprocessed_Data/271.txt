bayesian unification of gradient and bandit based learning accelerated global optimisation global optimization multi armed bandit on line learning multi strategy learning bandit based optimisation scheme remarkable advantage over gradient based approach due their global perspective which eliminates danger of getting stuck local optimum however continuous optimisation problem or problem with large number of action bandit based approach hindered by slow learning gradient based approach other hand navigate quickly high dimensional continuous space through local optimisation following gradient fine grained step however apart from being susceptible local optimum these scheme also less suited online learning due their reliance extensive trial and error before optimum identified contrast bandit algorithm seek identify optimal action global optimum few step possible this paper propose bayesian approach that unifies above two distinct paradigm one single framework with aim of combining their advantage heart of our approach find stochastic linear approximation of function optimised where both gradient and value of function explicitly captured this model allows u learn from both noisy function and gradient observation well predicting these property across action space support optimisation further propose an accompanying bandit driven exploration scheme that us bayesian credible bound trade off exploration against exploitation our empirical result demonstrate that by unifying bandit and gradient based learning one obtains consistently improved performance across wide spectrum of problem environment furthermore even when gradient feedback is unavailable flexibility of our model including gradient prediction still allows u outperform competing approach although with smaller margin