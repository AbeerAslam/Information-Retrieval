direct multiclass boosting using base classifier posterior probability estimate machine learning boosting margin multiclass classification present new multiclass boosting algorithm called adaboost bg like original freund and shapire s adaboost algorithm it aggregate tree but instead of using their misclassification error it take into account margin of observation which may seen confidence measure of their prediction rather then their correctness prove efficiency of our algorithm by simulation and compare it similar approach known minimize global margin of final classifier