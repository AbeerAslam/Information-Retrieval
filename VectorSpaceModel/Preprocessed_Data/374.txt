parametric exponential linear unit deep convolutional neural network activation function deep learning object recognition is an important task improving ability of visual system perform complex scene understanding recently exponential linear unit elu been proposed key component managing bias shift convolutional neural network cnns but defines parameter that must set by hand this paper propose learning parameterization of elu order learn proper activation shape each layer cnns our result mnist cifar 10 100 and imagenet datasets using nin overfeat all cnn and resnet network indicate that our proposed parametric elu pelu better performance than non parametric elu observed much 7 28 relative error improvement imagenet with nin network with only 0 0003 parameter increase our visual examination of non linear behavior adopted by vgg using pelu show that network took advantage of added flexibility by learning different activation different layer