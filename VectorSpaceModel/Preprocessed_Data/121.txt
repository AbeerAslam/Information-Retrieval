effect of dataset size training tweet sentiment classifier sentiment analysis tweet mining classification big data using automated method of labeling tweet sentiment large volume of tweet labeled and used train classifier million of tweet could used train classifier however doing so is computationally expensive thus it is valuable establish how many tweet should utilized train classifier since using additional instance with gain performance is waste of resource this study seek find out how many tweet needed before significant improvement observed sentiment analysis when adding additional instance train and evaluate classifier using c4 5 decision tree nave bayes 5 nearest neighbor and radial basis function network with seven datasets varying from 1000 243 000 instance model trained using four run of 5 fold cross validation additionally conduct statistical test verify our observation and examine impact of limiting feature using frequency learner were found improve with dataset size with nave bayes being best performing learner found that nave bayes did not significantly benefit from using more than 81 000 instance best of our knowledge this is first study investigate how learner scale respect dataset size with result verified using statistical test and multiple model trained each learner and dataset size additionally investigated using feature frequency greatly reduce data grid size with either small increase or decrease classifier performance depending choice of learner