decaying potential field neural network an approach parallelizing topologically indicative mapping exemplar self organization parallelization recall of data potential mapping methodology aim make sense or connection from hard data human mind is able efficiently and quickly process image through visual cortex part due it parallel nature basic kohonen self organizing feature map sofm is one example of mapping methodology class of neural network that doe this very well optimally result is nicely mapped neural network representative of data set however sofms not translate parallelized architecture very well problem stem from neighborhood that established between neuron creating race condition updating winning neuron propose fully parallelized mapping architecture based loosely sofm called decaying potential field neural network dpfnn show that dpfnn us neuron that computationally uncoupled but symbolically linked through analysis show this allows neuron reach convergence with having only passive data dependency each other opposed hazard generating direct dependency created this network closely reflect efficiency and speed of parallel approach with result that rival or exceed those of similar topological network such sofm