resampling based variable selection with lasso p n and partially linear model feature selection variable selection big data high dimensional data lasso regression non linearity linear model of regression function is widely used and perhaps most case highly unrealistic simplifying assumption when proposing consistent variable selection method large and highly dimensional datasets this paper study what happens from theoretical point of view when variable selection method assumes linear regression function and underlying ground truth model is composed of linear and non linear term that is most partially linear demonstrate consistency of lasso method when model is partially linear however note that algorithm tends increase even more number of selected false positive partially linear model when given few training sample that is usually because value of small group of sample happen explain variation coming from non linear part of response function and noise using linear combination of wrong predictor demonstrate theoretically that false positive likely selected by lasso method due small proportion of sample which happen explain some variation response variable show that this property implies that if run lasso several slightly smaller size data replication sampled without replacement and intersect result likely reduce number of false positive without losing already selected true positive propose novel consistent variable selection algorithm based this property and show it outperform other variable selection method synthetic datasets of linear and partially linear model and datasets from uci machine learning repository