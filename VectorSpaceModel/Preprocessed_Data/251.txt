predicting future agent motion dynamic environment activity forecasting inverse reinforcement learning multiple object tracking understanding activity of people monitored environment is topic of active research motivated by application requiring context awareness inferring future agent motion is useful not only improving tracking accuracy but also planning an interactive motion task despite rapid advance area of activity forecasting many state of the art method still cumbersome use realistic robot this is due requirement of having good semantic scene and map labelling well assumption made regarding possible goal and type of motion many emerging application require robot with modest sensory and computational ability robustly perform such activity forecasting high density and dynamic environment address this by combining novel multi camera tracking method efficient multi resolution representation of state and standard inverse reinforcement learning irl technique demonstrate performance that is better than state of the art literature this framework irl method us agent trajectory from distributed tracker and estimate reward function within markov decision process mdp model this reward function then used estimate agent s motion future novel task instance present empirical experiment using data gathered our own lab and external corpus virat based which find that our algorithm is not only efficiently implementable resource constrained platform but is also competitive term of accuracy with state of the art alternative e g 20 better than result reported 1