improved knn rule small training set error analysis training prediction algorithm data model computer science educational institution electronic mail traditional k nn classification rule predicts label based most common label of k nearest neighbor plurality rule it is known that plurality rule is optimal when number of example tends infinity this paper show that plurality rule is sub optimal when number of label is large and number of example is small propose simple k nn rule that take into account label of of neighbor rather than just most common label present number of experiment both synthetic datasets and real world datasets including mnist and svhn show that our new rule achieve lower error rate compared majority rule many case